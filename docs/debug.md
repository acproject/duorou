[DEBUG] GGUFParser: Read tensor name: v.blk.21.ffn_down.weight
[DEBUG] GGUFParser: Reading tensor 572/858
[DEBUG] GGUFParser: Read tensor name: v.blk.21.ffn_gate.bias
[DEBUG] GGUFParser: Reading tensor 573/858
[DEBUG] GGUFParser: Read tensor name: v.blk.21.ffn_gate.weight
[DEBUG] GGUFParser: Reading tensor 574/858
[DEBUG] GGUFParser: Read tensor name: v.blk.21.ffn_up.bias
[DEBUG] GGUFParser: Reading tensor 575/858
[DEBUG] GGUFParser: Read tensor name: v.blk.21.ffn_up.weight
[DEBUG] GGUFParser: Reading tensor 576/858
[DEBUG] GGUFParser: Read tensor name: v.blk.21.ln1.weight
[DEBUG] GGUFParser: Reading tensor 577/858
[DEBUG] GGUFParser: Read tensor name: v.blk.21.ln2.weight
[DEBUG] GGUFParser: Reading tensor 578/858
[DEBUG] GGUFParser: Read tensor name: v.blk.22.attn_out.bias
[DEBUG] GGUFParser: Reading tensor 579/858
[DEBUG] GGUFParser: Read tensor name: v.blk.22.attn_out.weight
[DEBUG] GGUFParser: Reading tensor 580/858
[DEBUG] GGUFParser: Read tensor name: v.blk.22.attn_q.bias
[DEBUG] GGUFParser: Reading tensor 581/858
[DEBUG] GGUFParser: Read tensor name: v.blk.22.attn_k.bias
[DEBUG] GGUFParser: Reading tensor 582/858
[DEBUG] GGUFParser: Read tensor name: v.blk.22.attn_v.bias
[DEBUG] GGUFParser: Reading tensor 583/858
[DEBUG] GGUFParser: Read tensor name: v.blk.22.attn_q.weight
[DEBUG] GGUFParser: Reading tensor 584/858
[DEBUG] GGUFParser: Read tensor name: v.blk.22.attn_k.weight
[DEBUG] GGUFParser: Reading tensor 585/858
[DEBUG] GGUFParser: Read tensor name: v.blk.22.attn_v.weight
[DEBUG] GGUFParser: Reading tensor 586/858
[DEBUG] GGUFParser: Read tensor name: v.blk.22.ffn_down.bias
[DEBUG] GGUFParser: Reading tensor 587/858
[DEBUG] GGUFParser: Read tensor name: v.blk.22.ffn_down.weight
[DEBUG] GGUFParser: Reading tensor 588/858
[DEBUG] GGUFParser: Read tensor name: v.blk.22.ffn_gate.bias
[DEBUG] GGUFParser: Reading tensor 589/858
[DEBUG] GGUFParser: Read tensor name: v.blk.22.ffn_gate.weight
[DEBUG] GGUFParser: Reading tensor 590/858
[DEBUG] GGUFParser: Read tensor name: v.blk.22.ffn_up.bias
[DEBUG] GGUFParser: Reading tensor 591/858
[DEBUG] GGUFParser: Read tensor name: v.blk.22.ffn_up.weight
[DEBUG] GGUFParser: Reading tensor 592/858
[DEBUG] GGUFParser: Read tensor name: v.blk.22.ln1.weight
[DEBUG] GGUFParser: Reading tensor 593/858
[DEBUG] GGUFParser: Read tensor name: v.blk.22.ln2.weight
[DEBUG] GGUFParser: Reading tensor 594/858
[DEBUG] GGUFParser: Read tensor name: v.blk.23.attn_out.bias
[DEBUG] GGUFParser: Reading tensor 595/858
[DEBUG] GGUFParser: Read tensor name: v.blk.23.attn_out.weight
[DEBUG] GGUFParser: Reading tensor 596/858
[DEBUG] GGUFParser: Read tensor name: v.blk.23.attn_q.bias
[DEBUG] GGUFParser: Reading tensor 597/858
[DEBUG] GGUFParser: Read tensor name: v.blk.23.attn_k.bias
[DEBUG] GGUFParser: Reading tensor 598/858
[DEBUG] GGUFParser: Read tensor name: v.blk.23.attn_v.bias
[DEBUG] GGUFParser: Reading tensor 599/858
[DEBUG] GGUFParser: Read tensor name: v.blk.23.attn_q.weight
[DEBUG] GGUFParser: Reading tensor 600/858
[DEBUG] GGUFParser: Read tensor name: v.blk.23.attn_k.weight
[DEBUG] GGUFParser: Reading tensor 601/858
[DEBUG] GGUFParser: Read tensor name: v.blk.23.attn_v.weight
[DEBUG] GGUFParser: Reading tensor 602/858
[DEBUG] GGUFParser: Read tensor name: v.blk.23.ffn_down.bias
[DEBUG] GGUFParser: Reading tensor 603/858
[DEBUG] GGUFParser: Read tensor name: v.blk.23.ffn_down.weight
[DEBUG] GGUFParser: Reading tensor 604/858
[DEBUG] GGUFParser: Read tensor name: v.blk.23.ffn_gate.bias
[DEBUG] GGUFParser: Reading tensor 605/858
[DEBUG] GGUFParser: Read tensor name: v.blk.23.ffn_gate.weight
[DEBUG] GGUFParser: Reading tensor 606/858
[DEBUG] GGUFParser: Read tensor name: v.blk.23.ffn_up.bias
[DEBUG] GGUFParser: Reading tensor 607/858
[DEBUG] GGUFParser: Read tensor name: v.blk.23.ffn_up.weight
[DEBUG] GGUFParser: Reading tensor 608/858
[DEBUG] GGUFParser: Read tensor name: v.blk.23.ln1.weight
[DEBUG] GGUFParser: Reading tensor 609/858
[DEBUG] GGUFParser: Read tensor name: v.blk.23.ln2.weight
[DEBUG] GGUFParser: Reading tensor 610/858
[DEBUG] GGUFParser: Read tensor name: v.blk.24.attn_out.bias
[DEBUG] GGUFParser: Reading tensor 611/858
[DEBUG] GGUFParser: Read tensor name: v.blk.24.attn_out.weight
[DEBUG] GGUFParser: Reading tensor 612/858
[DEBUG] GGUFParser: Read tensor name: v.blk.24.attn_q.bias
[DEBUG] GGUFParser: Reading tensor 613/858
[DEBUG] GGUFParser: Read tensor name: v.blk.24.attn_k.bias
[DEBUG] GGUFParser: Reading tensor 614/858
[DEBUG] GGUFParser: Read tensor name: v.blk.24.attn_v.bias
[DEBUG] GGUFParser: Reading tensor 615/858
[DEBUG] GGUFParser: Read tensor name: v.blk.24.attn_q.weight
[DEBUG] GGUFParser: Reading tensor 616/858
[DEBUG] GGUFParser: Read tensor name: v.blk.24.attn_k.weight
[DEBUG] GGUFParser: Reading tensor 617/858
[DEBUG] GGUFParser: Read tensor name: v.blk.24.attn_v.weight
[DEBUG] GGUFParser: Reading tensor 618/858
[DEBUG] GGUFParser: Read tensor name: v.blk.24.ffn_down.bias
[DEBUG] GGUFParser: Reading tensor 619/858
[DEBUG] GGUFParser: Read tensor name: v.blk.24.ffn_down.weight
[DEBUG] GGUFParser: Reading tensor 620/858
[DEBUG] GGUFParser: Read tensor name: v.blk.24.ffn_gate.bias
[DEBUG] GGUFParser: Reading tensor 621/858
[DEBUG] GGUFParser: Read tensor name: v.blk.24.ffn_gate.weight
[DEBUG] GGUFParser: Reading tensor 622/858
[DEBUG] GGUFParser: Read tensor name: v.blk.24.ffn_up.bias
[DEBUG] GGUFParser: Reading tensor 623/858
[DEBUG] GGUFParser: Read tensor name: v.blk.24.ffn_up.weight
[DEBUG] GGUFParser: Reading tensor 624/858
[DEBUG] GGUFParser: Read tensor name: v.blk.24.ln1.weight
[DEBUG] GGUFParser: Reading tensor 625/858
[DEBUG] GGUFParser: Read tensor name: v.blk.24.ln2.weight
[DEBUG] GGUFParser: Reading tensor 626/858
[DEBUG] GGUFParser: Read tensor name: v.blk.25.attn_out.bias
[DEBUG] GGUFParser: Reading tensor 627/858
[DEBUG] GGUFParser: Read tensor name: v.blk.25.attn_out.weight
[DEBUG] GGUFParser: Reading tensor 628/858
[DEBUG] GGUFParser: Read tensor name: v.blk.25.attn_q.bias
[DEBUG] GGUFParser: Reading tensor 629/858
[DEBUG] GGUFParser: Read tensor name: v.blk.25.attn_k.bias
[DEBUG] GGUFParser: Reading tensor 630/858
[DEBUG] GGUFParser: Read tensor name: v.blk.25.attn_v.bias
[DEBUG] GGUFParser: Reading tensor 631/858
[DEBUG] GGUFParser: Read tensor name: v.blk.25.attn_q.weight
[DEBUG] GGUFParser: Reading tensor 632/858
[DEBUG] GGUFParser: Read tensor name: v.blk.25.attn_k.weight
[DEBUG] GGUFParser: Reading tensor 633/858
[DEBUG] GGUFParser: Read tensor name: v.blk.25.attn_v.weight
[DEBUG] GGUFParser: Reading tensor 634/858
[DEBUG] GGUFParser: Read tensor name: v.blk.25.ffn_down.bias
[DEBUG] GGUFParser: Reading tensor 635/858
[DEBUG] GGUFParser: Read tensor name: v.blk.25.ffn_down.weight
[DEBUG] GGUFParser: Reading tensor 636/858
[DEBUG] GGUFParser: Read tensor name: v.blk.25.ffn_gate.bias
[DEBUG] GGUFParser: Reading tensor 637/858
[DEBUG] GGUFParser: Read tensor name: v.blk.25.ffn_gate.weight
[DEBUG] GGUFParser: Reading tensor 638/858
[DEBUG] GGUFParser: Read tensor name: v.blk.25.ffn_up.bias
[DEBUG] GGUFParser: Reading tensor 639/858
[DEBUG] GGUFParser: Read tensor name: v.blk.25.ffn_up.weight
[DEBUG] GGUFParser: Reading tensor 640/858
[DEBUG] GGUFParser: Read tensor name: v.blk.25.ln1.weight
[DEBUG] GGUFParser: Reading tensor 641/858
[DEBUG] GGUFParser: Read tensor name: v.blk.25.ln2.weight
[DEBUG] GGUFParser: Reading tensor 642/858
[DEBUG] GGUFParser: Read tensor name: v.blk.26.attn_out.bias
[DEBUG] GGUFParser: Reading tensor 643/858
[DEBUG] GGUFParser: Read tensor name: v.blk.26.attn_out.weight
[DEBUG] GGUFParser: Reading tensor 644/858
[DEBUG] GGUFParser: Read tensor name: v.blk.26.attn_q.bias
[DEBUG] GGUFParser: Reading tensor 645/858
[DEBUG] GGUFParser: Read tensor name: v.blk.26.attn_k.bias
[DEBUG] GGUFParser: Reading tensor 646/858
[DEBUG] GGUFParser: Read tensor name: v.blk.26.attn_v.bias
[DEBUG] GGUFParser: Reading tensor 647/858
[DEBUG] GGUFParser: Read tensor name: v.blk.26.attn_q.weight
[DEBUG] GGUFParser: Reading tensor 648/858
[DEBUG] GGUFParser: Read tensor name: v.blk.26.attn_k.weight
[DEBUG] GGUFParser: Reading tensor 649/858
[DEBUG] GGUFParser: Read tensor name: v.blk.26.attn_v.weight
[DEBUG] GGUFParser: Reading tensor 650/858
[DEBUG] GGUFParser: Read tensor name: v.blk.26.ffn_down.bias
[DEBUG] GGUFParser: Reading tensor 651/858
[DEBUG] GGUFParser: Read tensor name: v.blk.26.ffn_down.weight
[DEBUG] GGUFParser: Reading tensor 652/858
[DEBUG] GGUFParser: Read tensor name: v.blk.26.ffn_gate.bias
[DEBUG] GGUFParser: Reading tensor 653/858
[DEBUG] GGUFParser: Read tensor name: v.blk.26.ffn_gate.weight
[DEBUG] GGUFParser: Reading tensor 654/858
[DEBUG] GGUFParser: Read tensor name: v.blk.26.ffn_up.bias
[DEBUG] GGUFParser: Reading tensor 655/858
[DEBUG] GGUFParser: Read tensor name: v.blk.26.ffn_up.weight
[DEBUG] GGUFParser: Reading tensor 656/858
[DEBUG] GGUFParser: Read tensor name: v.blk.26.ln1.weight
[DEBUG] GGUFParser: Reading tensor 657/858
[DEBUG] GGUFParser: Read tensor name: v.blk.26.ln2.weight
[DEBUG] GGUFParser: Reading tensor 658/858
[DEBUG] GGUFParser: Read tensor name: v.blk.27.attn_out.bias
[DEBUG] GGUFParser: Reading tensor 659/858
[DEBUG] GGUFParser: Read tensor name: v.blk.27.attn_out.weight
[DEBUG] GGUFParser: Reading tensor 660/858
[DEBUG] GGUFParser: Read tensor name: v.blk.27.attn_q.bias
[DEBUG] GGUFParser: Reading tensor 661/858
[DEBUG] GGUFParser: Read tensor name: v.blk.27.attn_k.bias
[DEBUG] GGUFParser: Reading tensor 662/858
[DEBUG] GGUFParser: Read tensor name: v.blk.27.attn_v.bias
[DEBUG] GGUFParser: Reading tensor 663/858
[DEBUG] GGUFParser: Read tensor name: v.blk.27.attn_q.weight
[DEBUG] GGUFParser: Reading tensor 664/858
[DEBUG] GGUFParser: Read tensor name: v.blk.27.attn_k.weight
[DEBUG] GGUFParser: Reading tensor 665/858
[DEBUG] GGUFParser: Read tensor name: v.blk.27.attn_v.weight
[DEBUG] GGUFParser: Reading tensor 666/858
[DEBUG] GGUFParser: Read tensor name: v.blk.27.ffn_down.bias
[DEBUG] GGUFParser: Reading tensor 667/858
[DEBUG] GGUFParser: Read tensor name: v.blk.27.ffn_down.weight
[DEBUG] GGUFParser: Reading tensor 668/858
[DEBUG] GGUFParser: Read tensor name: v.blk.27.ffn_gate.bias
[DEBUG] GGUFParser: Reading tensor 669/858
[DEBUG] GGUFParser: Read tensor name: v.blk.27.ffn_gate.weight
[DEBUG] GGUFParser: Reading tensor 670/858
[DEBUG] GGUFParser: Read tensor name: v.blk.27.ffn_up.bias
[DEBUG] GGUFParser: Reading tensor 671/858
[DEBUG] GGUFParser: Read tensor name: v.blk.27.ffn_up.weight
[DEBUG] GGUFParser: Reading tensor 672/858
[DEBUG] GGUFParser: Read tensor name: v.blk.27.ln1.weight
[DEBUG] GGUFParser: Reading tensor 673/858
[DEBUG] GGUFParser: Read tensor name: v.blk.27.ln2.weight
[DEBUG] GGUFParser: Reading tensor 674/858
[DEBUG] GGUFParser: Read tensor name: v.blk.28.attn_out.bias
[DEBUG] GGUFParser: Reading tensor 675/858
[DEBUG] GGUFParser: Read tensor name: v.blk.28.attn_out.weight
[DEBUG] GGUFParser: Reading tensor 676/858
[DEBUG] GGUFParser: Read tensor name: v.blk.28.attn_q.bias
[DEBUG] GGUFParser: Reading tensor 677/858
[DEBUG] GGUFParser: Read tensor name: v.blk.28.attn_k.bias
[DEBUG] GGUFParser: Reading tensor 678/858
[DEBUG] GGUFParser: Read tensor name: v.blk.28.attn_v.bias
[DEBUG] GGUFParser: Reading tensor 679/858
[DEBUG] GGUFParser: Read tensor name: v.blk.28.attn_q.weight
[DEBUG] GGUFParser: Reading tensor 680/858
[DEBUG] GGUFParser: Read tensor name: v.blk.28.attn_k.weight
[DEBUG] GGUFParser: Reading tensor 681/858
[DEBUG] GGUFParser: Read tensor name: v.blk.28.attn_v.weight
[DEBUG] GGUFParser: Reading tensor 682/858
[DEBUG] GGUFParser: Read tensor name: v.blk.28.ffn_down.bias
[DEBUG] GGUFParser: Reading tensor 683/858
[DEBUG] GGUFParser: Read tensor name: v.blk.28.ffn_down.weight
[DEBUG] GGUFParser: Reading tensor 684/858
[DEBUG] GGUFParser: Read tensor name: v.blk.28.ffn_gate.bias
[DEBUG] GGUFParser: Reading tensor 685/858
[DEBUG] GGUFParser: Read tensor name: v.blk.28.ffn_gate.weight
[DEBUG] GGUFParser: Reading tensor 686/858
[DEBUG] GGUFParser: Read tensor name: v.blk.28.ffn_up.bias
[DEBUG] GGUFParser: Reading tensor 687/858
[DEBUG] GGUFParser: Read tensor name: v.blk.28.ffn_up.weight
[DEBUG] GGUFParser: Reading tensor 688/858
[DEBUG] GGUFParser: Read tensor name: v.blk.28.ln1.weight
[DEBUG] GGUFParser: Reading tensor 689/858
[DEBUG] GGUFParser: Read tensor name: v.blk.28.ln2.weight
[DEBUG] GGUFParser: Reading tensor 690/858
[DEBUG] GGUFParser: Read tensor name: v.blk.29.attn_out.bias
[DEBUG] GGUFParser: Reading tensor 691/858
[DEBUG] GGUFParser: Read tensor name: v.blk.29.attn_out.weight
[DEBUG] GGUFParser: Reading tensor 692/858
[DEBUG] GGUFParser: Read tensor name: v.blk.29.attn_q.bias
[DEBUG] GGUFParser: Reading tensor 693/858
[DEBUG] GGUFParser: Read tensor name: v.blk.29.attn_k.bias
[DEBUG] GGUFParser: Reading tensor 694/858
[DEBUG] GGUFParser: Read tensor name: v.blk.29.attn_v.bias
[DEBUG] GGUFParser: Reading tensor 695/858
[DEBUG] GGUFParser: Read tensor name: v.blk.29.attn_q.weight
[DEBUG] GGUFParser: Reading tensor 696/858
[DEBUG] GGUFParser: Read tensor name: v.blk.29.attn_k.weight
[DEBUG] GGUFParser: Reading tensor 697/858
[DEBUG] GGUFParser: Read tensor name: v.blk.29.attn_v.weight
[DEBUG] GGUFParser: Reading tensor 698/858
[DEBUG] GGUFParser: Read tensor name: v.blk.29.ffn_down.bias
[DEBUG] GGUFParser: Reading tensor 699/858
[DEBUG] GGUFParser: Read tensor name: v.blk.29.ffn_down.weight
[DEBUG] GGUFParser: Reading tensor 700/858
[DEBUG] GGUFParser: Read tensor name: v.blk.29.ffn_gate.bias
[DEBUG] GGUFParser: Reading tensor 701/858
[DEBUG] GGUFParser: Read tensor name: v.blk.29.ffn_gate.weight
[DEBUG] GGUFParser: Reading tensor 702/858
[DEBUG] GGUFParser: Read tensor name: v.blk.29.ffn_up.bias
[DEBUG] GGUFParser: Reading tensor 703/858
[DEBUG] GGUFParser: Read tensor name: v.blk.29.ffn_up.weight
[DEBUG] GGUFParser: Reading tensor 704/858
[DEBUG] GGUFParser: Read tensor name: v.blk.29.ln1.weight
[DEBUG] GGUFParser: Reading tensor 705/858
[DEBUG] GGUFParser: Read tensor name: v.blk.29.ln2.weight
[DEBUG] GGUFParser: Reading tensor 706/858
[DEBUG] GGUFParser: Read tensor name: v.blk.3.attn_out.bias
[DEBUG] GGUFParser: Reading tensor 707/858
[DEBUG] GGUFParser: Read tensor name: v.blk.3.attn_out.weight
[DEBUG] GGUFParser: Reading tensor 708/858
[DEBUG] GGUFParser: Read tensor name: v.blk.3.attn_q.bias
[DEBUG] GGUFParser: Reading tensor 709/858
[DEBUG] GGUFParser: Read tensor name: v.blk.3.attn_k.bias
[DEBUG] GGUFParser: Reading tensor 710/858
[DEBUG] GGUFParser: Read tensor name: v.blk.3.attn_v.bias
[DEBUG] GGUFParser: Reading tensor 711/858
[DEBUG] GGUFParser: Read tensor name: v.blk.3.attn_q.weight
[DEBUG] GGUFParser: Reading tensor 712/858
[DEBUG] GGUFParser: Read tensor name: v.blk.3.attn_k.weight
[DEBUG] GGUFParser: Reading tensor 713/858
[DEBUG] GGUFParser: Read tensor name: v.blk.3.attn_v.weight
[DEBUG] GGUFParser: Reading tensor 714/858
[DEBUG] GGUFParser: Read tensor name: v.blk.3.ffn_down.bias
[DEBUG] GGUFParser: Reading tensor 715/858
[DEBUG] GGUFParser: Read tensor name: v.blk.3.ffn_down.weight
[DEBUG] GGUFParser: Reading tensor 716/858
[DEBUG] GGUFParser: Read tensor name: v.blk.3.ffn_gate.bias
[DEBUG] GGUFParser: Reading tensor 717/858
[DEBUG] GGUFParser: Read tensor name: v.blk.3.ffn_gate.weight
[DEBUG] GGUFParser: Reading tensor 718/858
[DEBUG] GGUFParser: Read tensor name: v.blk.3.ffn_up.bias
[DEBUG] GGUFParser: Reading tensor 719/858
[DEBUG] GGUFParser: Read tensor name: v.blk.3.ffn_up.weight
[DEBUG] GGUFParser: Reading tensor 720/858
[DEBUG] GGUFParser: Read tensor name: v.blk.3.ln1.weight
[DEBUG] GGUFParser: Reading tensor 721/858
[DEBUG] GGUFParser: Read tensor name: v.blk.3.ln2.weight
[DEBUG] GGUFParser: Reading tensor 722/858
[DEBUG] GGUFParser: Read tensor name: v.blk.30.attn_out.bias
[DEBUG] GGUFParser: Reading tensor 723/858
[DEBUG] GGUFParser: Read tensor name: v.blk.30.attn_out.weight
[DEBUG] GGUFParser: Reading tensor 724/858
[DEBUG] GGUFParser: Read tensor name: v.blk.30.attn_q.bias
[DEBUG] GGUFParser: Reading tensor 725/858
[DEBUG] GGUFParser: Read tensor name: v.blk.30.attn_k.bias
[DEBUG] GGUFParser: Reading tensor 726/858
[DEBUG] GGUFParser: Read tensor name: v.blk.30.attn_v.bias
[DEBUG] GGUFParser: Reading tensor 727/858
[DEBUG] GGUFParser: Read tensor name: v.blk.30.attn_q.weight
[DEBUG] GGUFParser: Reading tensor 728/858
[DEBUG] GGUFParser: Read tensor name: v.blk.30.attn_k.weight
[DEBUG] GGUFParser: Reading tensor 729/858
[DEBUG] GGUFParser: Read tensor name: v.blk.30.attn_v.weight
[DEBUG] GGUFParser: Reading tensor 730/858
[DEBUG] GGUFParser: Read tensor name: v.blk.30.ffn_down.bias
[DEBUG] GGUFParser: Reading tensor 731/858
[DEBUG] GGUFParser: Read tensor name: v.blk.30.ffn_down.weight
[DEBUG] GGUFParser: Reading tensor 732/858
[DEBUG] GGUFParser: Read tensor name: v.blk.30.ffn_gate.bias
[DEBUG] GGUFParser: Reading tensor 733/858
[DEBUG] GGUFParser: Read tensor name: v.blk.30.ffn_gate.weight
[DEBUG] GGUFParser: Reading tensor 734/858
[DEBUG] GGUFParser: Read tensor name: v.blk.30.ffn_up.bias
[DEBUG] GGUFParser: Reading tensor 735/858
[DEBUG] GGUFParser: Read tensor name: v.blk.30.ffn_up.weight
[DEBUG] GGUFParser: Reading tensor 736/858
[DEBUG] GGUFParser: Read tensor name: v.blk.30.ln1.weight
[DEBUG] GGUFParser: Reading tensor 737/858
[DEBUG] GGUFParser: Read tensor name: v.blk.30.ln2.weight
[DEBUG] GGUFParser: Reading tensor 738/858
[DEBUG] GGUFParser: Read tensor name: v.blk.31.attn_out.bias
[DEBUG] GGUFParser: Reading tensor 739/858
[DEBUG] GGUFParser: Read tensor name: v.blk.31.attn_out.weight
[DEBUG] GGUFParser: Reading tensor 740/858
[DEBUG] GGUFParser: Read tensor name: v.blk.31.attn_q.bias
[DEBUG] GGUFParser: Reading tensor 741/858
[DEBUG] GGUFParser: Read tensor name: v.blk.31.attn_k.bias
[DEBUG] GGUFParser: Reading tensor 742/858
[DEBUG] GGUFParser: Read tensor name: v.blk.31.attn_v.bias
[DEBUG] GGUFParser: Reading tensor 743/858
[DEBUG] GGUFParser: Read tensor name: v.blk.31.attn_q.weight
[DEBUG] GGUFParser: Reading tensor 744/858
[DEBUG] GGUFParser: Read tensor name: v.blk.31.attn_k.weight
[DEBUG] GGUFParser: Reading tensor 745/858
[DEBUG] GGUFParser: Read tensor name: v.blk.31.attn_v.weight
[DEBUG] GGUFParser: Reading tensor 746/858
[DEBUG] GGUFParser: Read tensor name: v.blk.31.ffn_down.bias
[DEBUG] GGUFParser: Reading tensor 747/858
[DEBUG] GGUFParser: Read tensor name: v.blk.31.ffn_down.weight
[DEBUG] GGUFParser: Reading tensor 748/858
[DEBUG] GGUFParser: Read tensor name: v.blk.31.ffn_gate.bias
[DEBUG] GGUFParser: Reading tensor 749/858
[DEBUG] GGUFParser: Read tensor name: v.blk.31.ffn_gate.weight
[DEBUG] GGUFParser: Reading tensor 750/858
[DEBUG] GGUFParser: Read tensor name: v.blk.31.ffn_up.bias
[DEBUG] GGUFParser: Reading tensor 751/858
[DEBUG] GGUFParser: Read tensor name: v.blk.31.ffn_up.weight
[DEBUG] GGUFParser: Reading tensor 752/858
[DEBUG] GGUFParser: Read tensor name: v.blk.31.ln1.weight
[DEBUG] GGUFParser: Reading tensor 753/858
[DEBUG] GGUFParser: Read tensor name: v.blk.31.ln2.weight
[DEBUG] GGUFParser: Reading tensor 754/858
[DEBUG] GGUFParser: Read tensor name: v.blk.4.attn_out.bias
[DEBUG] GGUFParser: Reading tensor 755/858
[DEBUG] GGUFParser: Read tensor name: v.blk.4.attn_out.weight
[DEBUG] GGUFParser: Reading tensor 756/858
[DEBUG] GGUFParser: Read tensor name: v.blk.4.attn_q.bias
[DEBUG] GGUFParser: Reading tensor 757/858
[DEBUG] GGUFParser: Read tensor name: v.blk.4.attn_k.bias
[DEBUG] GGUFParser: Reading tensor 758/858
[DEBUG] GGUFParser: Read tensor name: v.blk.4.attn_v.bias
[DEBUG] GGUFParser: Reading tensor 759/858
[DEBUG] GGUFParser: Read tensor name: v.blk.4.attn_q.weight
[DEBUG] GGUFParser: Reading tensor 760/858
[DEBUG] GGUFParser: Read tensor name: v.blk.4.attn_k.weight
[DEBUG] GGUFParser: Reading tensor 761/858
[DEBUG] GGUFParser: Read tensor name: v.blk.4.attn_v.weight
[DEBUG] GGUFParser: Reading tensor 762/858
[DEBUG] GGUFParser: Read tensor name: v.blk.4.ffn_down.bias
[DEBUG] GGUFParser: Reading tensor 763/858
[DEBUG] GGUFParser: Read tensor name: v.blk.4.ffn_down.weight
[DEBUG] GGUFParser: Reading tensor 764/858
[DEBUG] GGUFParser: Read tensor name: v.blk.4.ffn_gate.bias
[DEBUG] GGUFParser: Reading tensor 765/858
[DEBUG] GGUFParser: Read tensor name: v.blk.4.ffn_gate.weight
[DEBUG] GGUFParser: Reading tensor 766/858
[DEBUG] GGUFParser: Read tensor name: v.blk.4.ffn_up.bias
[DEBUG] GGUFParser: Reading tensor 767/858
[DEBUG] GGUFParser: Read tensor name: v.blk.4.ffn_up.weight
[DEBUG] GGUFParser: Reading tensor 768/858
[DEBUG] GGUFParser: Read tensor name: v.blk.4.ln1.weight
[DEBUG] GGUFParser: Reading tensor 769/858
[DEBUG] GGUFParser: Read tensor name: v.blk.4.ln2.weight
[DEBUG] GGUFParser: Reading tensor 770/858
[DEBUG] GGUFParser: Read tensor name: v.blk.5.attn_out.bias
[DEBUG] GGUFParser: Reading tensor 771/858
[DEBUG] GGUFParser: Read tensor name: v.blk.5.attn_out.weight
[DEBUG] GGUFParser: Reading tensor 772/858
[DEBUG] GGUFParser: Read tensor name: v.blk.5.attn_q.bias
[DEBUG] GGUFParser: Reading tensor 773/858
[DEBUG] GGUFParser: Read tensor name: v.blk.5.attn_k.bias
[DEBUG] GGUFParser: Reading tensor 774/858
[DEBUG] GGUFParser: Read tensor name: v.blk.5.attn_v.bias
[DEBUG] GGUFParser: Reading tensor 775/858
[DEBUG] GGUFParser: Read tensor name: v.blk.5.attn_q.weight
[DEBUG] GGUFParser: Reading tensor 776/858
[DEBUG] GGUFParser: Read tensor name: v.blk.5.attn_k.weight
[DEBUG] GGUFParser: Reading tensor 777/858
[DEBUG] GGUFParser: Read tensor name: v.blk.5.attn_v.weight
[DEBUG] GGUFParser: Reading tensor 778/858
[DEBUG] GGUFParser: Read tensor name: v.blk.5.ffn_down.bias
[DEBUG] GGUFParser: Reading tensor 779/858
[DEBUG] GGUFParser: Read tensor name: v.blk.5.ffn_down.weight
[DEBUG] GGUFParser: Reading tensor 780/858
[DEBUG] GGUFParser: Read tensor name: v.blk.5.ffn_gate.bias
[DEBUG] GGUFParser: Reading tensor 781/858
[DEBUG] GGUFParser: Read tensor name: v.blk.5.ffn_gate.weight
[DEBUG] GGUFParser: Reading tensor 782/858
[DEBUG] GGUFParser: Read tensor name: v.blk.5.ffn_up.bias
[DEBUG] GGUFParser: Reading tensor 783/858
[DEBUG] GGUFParser: Read tensor name: v.blk.5.ffn_up.weight
[DEBUG] GGUFParser: Reading tensor 784/858
[DEBUG] GGUFParser: Read tensor name: v.blk.5.ln1.weight
[DEBUG] GGUFParser: Reading tensor 785/858
[DEBUG] GGUFParser: Read tensor name: v.blk.5.ln2.weight
[DEBUG] GGUFParser: Reading tensor 786/858
[DEBUG] GGUFParser: Read tensor name: v.blk.6.attn_out.bias
[DEBUG] GGUFParser: Reading tensor 787/858
[DEBUG] GGUFParser: Read tensor name: v.blk.6.attn_out.weight
[DEBUG] GGUFParser: Reading tensor 788/858
[DEBUG] GGUFParser: Read tensor name: v.blk.6.attn_q.bias
[DEBUG] GGUFParser: Reading tensor 789/858
[DEBUG] GGUFParser: Read tensor name: v.blk.6.attn_k.bias
[DEBUG] GGUFParser: Reading tensor 790/858
[DEBUG] GGUFParser: Read tensor name: v.blk.6.attn_v.bias
[DEBUG] GGUFParser: Reading tensor 791/858
[DEBUG] GGUFParser: Read tensor name: v.blk.6.attn_q.weight
[DEBUG] GGUFParser: Reading tensor 792/858
[DEBUG] GGUFParser: Read tensor name: v.blk.6.attn_k.weight
[DEBUG] GGUFParser: Reading tensor 793/858
[DEBUG] GGUFParser: Read tensor name: v.blk.6.attn_v.weight
[DEBUG] GGUFParser: Reading tensor 794/858
[DEBUG] GGUFParser: Read tensor name: v.blk.6.ffn_down.bias
[DEBUG] GGUFParser: Reading tensor 795/858
[DEBUG] GGUFParser: Read tensor name: v.blk.6.ffn_down.weight
[DEBUG] GGUFParser: Reading tensor 796/858
[DEBUG] GGUFParser: Read tensor name: v.blk.6.ffn_gate.bias
[DEBUG] GGUFParser: Reading tensor 797/858
[DEBUG] GGUFParser: Read tensor name: v.blk.6.ffn_gate.weight
[DEBUG] GGUFParser: Reading tensor 798/858
[DEBUG] GGUFParser: Read tensor name: v.blk.6.ffn_up.bias
[DEBUG] GGUFParser: Reading tensor 799/858
[DEBUG] GGUFParser: Read tensor name: v.blk.6.ffn_up.weight
[DEBUG] GGUFParser: Reading tensor 800/858
[DEBUG] GGUFParser: Read tensor name: v.blk.6.ln1.weight
[DEBUG] GGUFParser: Reading tensor 801/858
[DEBUG] GGUFParser: Read tensor name: v.blk.6.ln2.weight
[DEBUG] GGUFParser: Reading tensor 802/858
[DEBUG] GGUFParser: Read tensor name: v.blk.7.attn_out.bias
[DEBUG] GGUFParser: Reading tensor 803/858
[DEBUG] GGUFParser: Read tensor name: v.blk.7.attn_out.weight
[DEBUG] GGUFParser: Reading tensor 804/858
[DEBUG] GGUFParser: Read tensor name: v.blk.7.attn_q.bias
[DEBUG] GGUFParser: Reading tensor 805/858
[DEBUG] GGUFParser: Read tensor name: v.blk.7.attn_k.bias
[DEBUG] GGUFParser: Reading tensor 806/858
[DEBUG] GGUFParser: Read tensor name: v.blk.7.attn_v.bias
[DEBUG] GGUFParser: Reading tensor 807/858
[DEBUG] GGUFParser: Read tensor name: v.blk.7.attn_q.weight
[DEBUG] GGUFParser: Reading tensor 808/858
[DEBUG] GGUFParser: Read tensor name: v.blk.7.attn_k.weight
[DEBUG] GGUFParser: Reading tensor 809/858
[DEBUG] GGUFParser: Read tensor name: v.blk.7.attn_v.weight
[DEBUG] GGUFParser: Reading tensor 810/858
[DEBUG] GGUFParser: Read tensor name: v.blk.7.ffn_down.bias
[DEBUG] GGUFParser: Reading tensor 811/858
[DEBUG] GGUFParser: Read tensor name: v.blk.7.ffn_down.weight
[DEBUG] GGUFParser: Reading tensor 812/858
[DEBUG] GGUFParser: Read tensor name: v.blk.7.ffn_gate.bias
[DEBUG] GGUFParser: Reading tensor 813/858
[DEBUG] GGUFParser: Read tensor name: v.blk.7.ffn_gate.weight
[DEBUG] GGUFParser: Reading tensor 814/858
[DEBUG] GGUFParser: Read tensor name: v.blk.7.ffn_up.bias
[DEBUG] GGUFParser: Reading tensor 815/858
[DEBUG] GGUFParser: Read tensor name: v.blk.7.ffn_up.weight
[DEBUG] GGUFParser: Reading tensor 816/858
[DEBUG] GGUFParser: Read tensor name: v.blk.7.ln1.weight
[DEBUG] GGUFParser: Reading tensor 817/858
[DEBUG] GGUFParser: Read tensor name: v.blk.7.ln2.weight
[DEBUG] GGUFParser: Reading tensor 818/858
[DEBUG] GGUFParser: Read tensor name: v.blk.8.attn_out.bias
[DEBUG] GGUFParser: Reading tensor 819/858
[DEBUG] GGUFParser: Read tensor name: v.blk.8.attn_out.weight
[DEBUG] GGUFParser: Reading tensor 820/858
[DEBUG] GGUFParser: Read tensor name: v.blk.8.attn_q.bias
[DEBUG] GGUFParser: Reading tensor 821/858
[DEBUG] GGUFParser: Read tensor name: v.blk.8.attn_k.bias
[DEBUG] GGUFParser: Reading tensor 822/858
[DEBUG] GGUFParser: Read tensor name: v.blk.8.attn_v.bias
[DEBUG] GGUFParser: Reading tensor 823/858
[DEBUG] GGUFParser: Read tensor name: v.blk.8.attn_q.weight
[DEBUG] GGUFParser: Reading tensor 824/858
[DEBUG] GGUFParser: Read tensor name: v.blk.8.attn_k.weight
[DEBUG] GGUFParser: Reading tensor 825/858
[DEBUG] GGUFParser: Read tensor name: v.blk.8.attn_v.weight
[DEBUG] GGUFParser: Reading tensor 826/858
[DEBUG] GGUFParser: Read tensor name: v.blk.8.ffn_down.bias
[DEBUG] GGUFParser: Reading tensor 827/858
[DEBUG] GGUFParser: Read tensor name: v.blk.8.ffn_down.weight
[DEBUG] GGUFParser: Reading tensor 828/858
[DEBUG] GGUFParser: Read tensor name: v.blk.8.ffn_gate.bias
[DEBUG] GGUFParser: Reading tensor 829/858
[DEBUG] GGUFParser: Read tensor name: v.blk.8.ffn_gate.weight
[DEBUG] GGUFParser: Reading tensor 830/858
[DEBUG] GGUFParser: Read tensor name: v.blk.8.ffn_up.bias
[DEBUG] GGUFParser: Reading tensor 831/858
[DEBUG] GGUFParser: Read tensor name: v.blk.8.ffn_up.weight
[DEBUG] GGUFParser: Reading tensor 832/858
[DEBUG] GGUFParser: Read tensor name: v.blk.8.ln1.weight
[DEBUG] GGUFParser: Reading tensor 833/858
[DEBUG] GGUFParser: Read tensor name: v.blk.8.ln2.weight
[DEBUG] GGUFParser: Reading tensor 834/858
[DEBUG] GGUFParser: Read tensor name: v.blk.9.attn_out.bias
[DEBUG] GGUFParser: Reading tensor 835/858
[DEBUG] GGUFParser: Read tensor name: v.blk.9.attn_out.weight
[DEBUG] GGUFParser: Reading tensor 836/858
[DEBUG] GGUFParser: Read tensor name: v.blk.9.attn_q.bias
[DEBUG] GGUFParser: Reading tensor 837/858
[DEBUG] GGUFParser: Read tensor name: v.blk.9.attn_k.bias
[DEBUG] GGUFParser: Reading tensor 838/858
[DEBUG] GGUFParser: Read tensor name: v.blk.9.attn_v.bias
[DEBUG] GGUFParser: Reading tensor 839/858
[DEBUG] GGUFParser: Read tensor name: v.blk.9.attn_q.weight
[DEBUG] GGUFParser: Reading tensor 840/858
[DEBUG] GGUFParser: Read tensor name: v.blk.9.attn_k.weight
[DEBUG] GGUFParser: Reading tensor 841/858
[DEBUG] GGUFParser: Read tensor name: v.blk.9.attn_v.weight
[DEBUG] GGUFParser: Reading tensor 842/858
[DEBUG] GGUFParser: Read tensor name: v.blk.9.ffn_down.bias
[DEBUG] GGUFParser: Reading tensor 843/858
[DEBUG] GGUFParser: Read tensor name: v.blk.9.ffn_down.weight
[DEBUG] GGUFParser: Reading tensor 844/858
[DEBUG] GGUFParser: Read tensor name: v.blk.9.ffn_gate.bias
[DEBUG] GGUFParser: Reading tensor 845/858
[DEBUG] GGUFParser: Read tensor name: v.blk.9.ffn_gate.weight
[DEBUG] GGUFParser: Reading tensor 846/858
[DEBUG] GGUFParser: Read tensor name: v.blk.9.ffn_up.bias
[DEBUG] GGUFParser: Reading tensor 847/858
[DEBUG] GGUFParser: Read tensor name: v.blk.9.ffn_up.weight
[DEBUG] GGUFParser: Reading tensor 848/858
[DEBUG] GGUFParser: Read tensor name: v.blk.9.ln1.weight
[DEBUG] GGUFParser: Reading tensor 849/858
[DEBUG] GGUFParser: Read tensor name: v.blk.9.ln2.weight
[DEBUG] GGUFParser: Reading tensor 850/858
[DEBUG] GGUFParser: Read tensor name: v.merger.ln_q.weight
[DEBUG] GGUFParser: Reading tensor 851/858
[DEBUG] GGUFParser: Read tensor name: v.merger.mlp.0.bias
[DEBUG] GGUFParser: Reading tensor 852/858
[DEBUG] GGUFParser: Read tensor name: v.merger.mlp.0.weight
[DEBUG] GGUFParser: Reading tensor 853/858
[DEBUG] GGUFParser: Read tensor name: v.merger.mlp.2.bias
[DEBUG] GGUFParser: Reading tensor 854/858
[DEBUG] GGUFParser: Read tensor name: v.merger.mlp.2.weight
[DEBUG] GGUFParser: Reading tensor 855/858
[DEBUG] GGUFParser: Read tensor name: v.patch_embd_0.weight
[DEBUG] GGUFParser: Reading tensor 856/858
[DEBUG] GGUFParser: Read tensor name: v.patch_embd_1.weight
[DEBUG] GGUFParser: Reading tensor 857/858
[DEBUG] GGUFParser: Read tensor name: output_norm.weight
[DEBUG] GGUFParser: Reading tensor 858/858
[DEBUG] GGUFParser: Read tensor name: output.weight
[DEBUG] GGUFParser: Read 858 tensor infos from mmap
[DEBUG] GGUFParser: Tensor info read successfully from mmap
[INFO] GGUFParser: Calculated vocab_size from tokens: 152064
[DEBUG] GGUFParser: Found rope.mrope_section metadata, data size: 24 bytes
[DEBUG] GGUFParser: rope.mrope_section array length: 3
[DEBUG] GGUFParser: Successfully parsed rope.mrope_section with 0 elements
[DEBUG] GGUFParser: Found vision.fullatt_block_indexes metadata, data size: 28 bytes
[DEBUG] GGUFParser: vision.fullatt_block_indexes array length: 4
[DEBUG] GGUFParser: Successfully parsed vision.fullatt_block_indexes with 0 elements
[INFO] GGUFParser: Parsed architecture: qwen25vl
[INFO] GGUFParser:   Context length: 128000
[INFO] GGUFParser:   Embedding length: 3584
[INFO] GGUFParser:   Block count: 28
[INFO] GGUFParser:   Has vision: Yes
[DEBUG] GGUFParser: Architecture parsed successfully
[INFO] GGUFParser: Successfully parsed GGUF file with mmap: /Users/acproject/.ollama/models/blobs/sha256-a99b7f834d754b88f122d865f32758ba9f0994a83f8363df2c1e71c17605a025
[INFO] GGUFParser: Architecture: qwen25vl
[INFO] GGUFParser: Metadata keys: 36
[INFO] GGUFParser: Tensor count: 858
[INFO] OllamaModelManager: Using vocab_size from GGUF: 152064
[INFO] OllamaModelManager: Vocabulary test passed: 'test' -> token 1944 -> 'test'
[WARNING] OllamaModelManager: Unsupported tokenizer model type: gpt2, using BPE as fallback
Warning: Invalid regex pattern, using simple whitespace split: One of *?+{ was not preceded by a valid regular expression.
[INFO] OllamaModelManager: Successfully loaded vocabulary from GGUF: 152064 tokens, model: bpe
[DEBUG] GGUFParser: GGUFParser destroyed
[INFO] OllamaModelManager: Model registered: sha256-a99b7f834d754b88f122d865f32758ba9f0994a83f8363df2c1e71c17605a025 -> /Users/acproject/.ollama/models/blobs/sha256-a99b7f834d754b88f122d865f32758ba9f0994a83f8363df2c1e71c17605a025
[INFO] OllamaModelManager: Model alias registered: registry.ollama.ai/library/qwen2.5vl:7b -> /Users/acproject/.ollama/models/blobs/sha256-a99b7f834d754b88f122d865f32758ba9f0994a83f8363df2c1e71c17605a025
[DEBUG] OllamaModelImpl: Using registered model_id: sha256-a99b7f834d754b88f122d865f32758ba9f0994a83f8363df2c1e71c17605a025 for path: registry.ollama.ai/library/qwen2.5vl:7b
[DEBUG] Model Config:
[DEBUG]   hidden_size: 3584
[DEBUG]   num_attention_heads: 28
[DEBUG]   num_key_value_heads: 4
[DEBUG]   intermediate_size: 18944
[DEBUG]   max_position_embeddings: 32768
[DEBUG]   rope_theta: 1e+06
[DEBUG]   rms_norm_eps: 1e-06
[DEBUG] Initializing KV Cache (llama.cpp inspired)
[DEBUG] KV Cache memory calculation (llama.cpp style):
[DEBUG]   Available memory: 8 GB
[DEBUG]   Memory for KV cache: 2048 MB
[DEBUG]   Elements per layer: 512
[DEBUG]   Max sequence length: 18724
[DEBUG]   Original max_position_embeddings: 32768
[DEBUG]   Optimal cache length: 4096
[DEBUG]   head_dim: 128
[DEBUG]   kv_head_dim: 128
[DEBUG]   num_hidden_layers: 28
[DEBUG]   num_key_value_heads: 4
[DEBUG] Layer 0 KV cache shape: [1, 4096, 512]
[DEBUG] Layer 0 KV cache memory: 16 MB per layer
[DEBUG] Total estimated KV cache memory: 448 MB
[DEBUG] Layer 0 KV cache size: 2097152
[DEBUG] Layer 0 KV cache data size: 2097152
[DEBUG] KV Cache initialized for 28 layers with optimized memory usage
Qwen2.5-VL Modular Engine initialized successfully
[DEBUG] OllamaModelManager: Inference engine created and initialized for model: sha256-a99b7f834d754b88f122d865f32758ba9f0994a83f8363df2c1e71c17605a025
[INFO] Transformer weights initialized successfully
Model weights loaded successfully from: /Users/acproject/.ollama/models/blobs/sha256-a99b7f834d754b88f122d865f32758ba9f0994a83f8363df2c1e71c17605a025
[DEBUG] OllamaModelManager: engine->loadWeights() completed successfully
[INFO] OllamaModelManager: Model loaded successfully: sha256-a99b7f834d754b88f122d865f32758ba9f0994a83f8363df2c1e71c17605a025
[DEBUG] OllamaModelImpl: Setting loaded status to true
[DEBUG] OllamaModelImpl: Created TextGenerator with Ollama backend
[DEBUG] OllamaModelImpl::load completed successfully
[SUCCESS] Model loaded successfully: registry.ollama.ai/library/qwen2.5vl:7b (took 224293ms)
[DEBUG] ChatView: Model loaded successfully: registry.ollama.ai/library/qwen2.5vl:7b
[DEBUG] ChatView: Getting text generator for model: registry.ollama.ai/library/qwen2.5vl:7b
[DEBUG] ModelManager::getTextGenerator called for: registry.ollama.ai/library/qwen2.5vl:7b
[DEBUG] Model found in loaded_models_, attempting cast to OllamaModelImpl
[DEBUG] Successfully cast to OllamaModelImpl, calling getTextGenerator()
[DEBUG] OllamaModelImpl::getTextGenerator returned: valid pointer
[DEBUG] TextGenerator::canGenerate() called - returning true (functionality enabled)
[DEBUG] ChatView: Starting text generation...
[DEBUG] TextGenerator::generate() called with prompt: 你好...
[DEBUG] Using Ollama model manager for inference
[DEBUG] Formatted prompt with ChatML: <|im_start|>user
你好<|im_end|>
<|im_start|>assistant
...
[DEBUG] OllamaModelManager: Tokenized '<|im_start|>user
你好<|im_end|>
<|im_start|>assistant
' to 28 tokens
[INFO] OllamaModelManager: Tokenized prompt into 28 tokens
[DEBUG] Qwen25VLModularEngine::generateText called with 28 input tokens, max_length=512
[DEBUG] Generation step 0/484 (total length: 28/512)
[DEBUG] Prefill mode with 28 tokens
[DEBUG] Applying embedding...
[DEBUG] applyEmbedding called
[DEBUG] Input IDs size: 28
[DEBUG] Input IDs: [151644, 872, 198, 108386, 151645, 198, 27, 91, 72, 76, ...]
[DEBUG] Embedding output shape: [1, 28, 3584]
[DEBUG] Config vocab_size: 152064
[DEBUG] Config hidden_size: 3584
[DEBUG] Embedding tensor created: size=100352, data_size=100352
[DEBUG] Token embeddings shape: [152064, 3584]
[DEBUG] Token embeddings size: 544997376
[DEBUG] Token embeddings data size: 544997376
[DEBUG] Expected embedding size: 544997376
[DEBUG] Embedding applied successfully
[DEBUG] Created attention mask
[DEBUG] Processing transformer layer 1/28
[DEBUG] Input tensor shape: [1, 28, 3584]
[DEBUG] RoPE output tensor shape: [1, 28, 3584]
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 3584], size=12845056, data_size=12845056
[DEBUG] Matrix dimensions: A(28x3584), B(3584x3584), batch_size=1
[DEBUG] Output shape: [1, 28, 3584]
[DEBUG] Result tensor created: size=100352, data_size=100352
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 512], size=1835008, data_size=1835008
[DEBUG] Matrix dimensions: A(28x3584), B(3584x512), batch_size=1
[DEBUG] Output shape: [1, 28, 512]
[DEBUG] Result tensor created: size=14336, data_size=14336
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 512], size=1835008, data_size=1835008
[DEBUG] Matrix dimensions: A(28x3584), B(3584x512), batch_size=1
[DEBUG] Output shape: [1, 28, 512]
[DEBUG] Result tensor created: size=14336, data_size=14336
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully
[DEBUG] Q projection shape: [1, 28, 3584]
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 28, 3584], num_heads=28, head_dim=128
[DEBUG] splitToHeads input data size: 100352, tensor size: 100352
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 28, 512], num_heads=4, head_dim=128
[DEBUG] splitToHeads input data size: 14336, tensor size: 14336
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 28, 512], num_heads=4, head_dim=128
[DEBUG] splitToHeads input data size: 14336, tensor size: 14336
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 4096, 512], num_heads=4, head_dim=128
[DEBUG] splitToHeads input data size: 2097152, tensor size: 2097152
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 4096, 512], num_heads=4, head_dim=128
[DEBUG] splitToHeads input data size: 2097152, tensor size: 2097152
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 3584], size=12845056, data_size=12845056
[DEBUG] Matrix dimensions: A(28x3584), B(3584x3584), batch_size=1
[DEBUG] Output shape: [1, 28, 3584]
[DEBUG] Result tensor created: size=100352, data_size=100352
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully
[DEBUG] Transformer layer 1 completed
[DEBUG] Processing transformer layer 2/28
[DEBUG] Input tensor shape: [1, 28, 3584]
[DEBUG] RoPE output tensor shape: [1, 28, 3584]
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 3584], size=12845056, data_size=12845056
[DEBUG] Matrix dimensions: A(28x3584), B(3584x3584), batch_size=1
[DEBUG] Output shape: [1, 28, 3584]
[DEBUG] Result tensor created: size=100352, data_size=100352
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 512], size=1835008, data_size=1835008
[DEBUG] Matrix dimensions: A(28x3584), B(3584x512), batch_size=1
[DEBUG] Output shape: [1, 28, 512]
[DEBUG] Result tensor created: size=14336, data_size=14336
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 512], size=1835008, data_size=1835008
[DEBUG] Matrix dimensions: A(28x3584), B(3584x512), batch_size=1
[DEBUG] Output shape: [1, 28, 512]
[DEBUG] Result tensor created: size=14336, data_size=14336
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully
[DEBUG] Q projection shape: [1, 28, 3584]
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 28, 3584], num_heads=28, head_dim=128
[DEBUG] splitToHeads input data size: 100352, tensor size: 100352
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 28, 512], num_heads=4, head_dim=128
[DEBUG] splitToHeads input data size: 14336, tensor size: 14336
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 28, 512], num_heads=4, head_dim=128
[DEBUG] splitToHeads input data size: 14336, tensor size: 14336
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 4096, 512], num_heads=4, head_dim=128
[DEBUG] splitToHeads input data size: 2097152, tensor size: 2097152
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 4096, 512], num_heads=4, head_dim=128
[DEBUG] splitToHeads input data size: 2097152, tensor size: 2097152
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 3584], size=12845056, data_size=12845056
[DEBUG] Matrix dimensions: A(28x3584), B(3584x3584), batch_size=1
[DEBUG] Output shape: [1, 28, 3584]
[DEBUG] Result tensor created: size=100352, data_size=100352
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully
[DEBUG] Transformer layer 2 completed
[DEBUG] Processing transformer layer 3/28
[DEBUG] Input tensor shape: [1, 28, 3584]
[DEBUG] RoPE output tensor shape: [1, 28, 3584]
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 3584], size=12845056, data_size=12845056
[DEBUG] Matrix dimensions: A(28x3584), B(3584x3584), batch_size=1
[DEBUG] Output shape: [1, 28, 3584]
[DEBUG] Result tensor created: size=100352, data_size=100352
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 512], size=1835008, data_size=1835008
[DEBUG] Matrix dimensions: A(28x3584), B(3584x512), batch_size=1
[DEBUG] Output shape: [1, 28, 512]
[DEBUG] Result tensor created: size=14336, data_size=14336
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 512], size=1835008, data_size=1835008
[DEBUG] Matrix dimensions: A(28x3584), B(3584x512), batch_size=1
[DEBUG] Output shape: [1, 28, 512]
[DEBUG] Result tensor created: size=14336, data_size=14336
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully
[DEBUG] Q projection shape: [1, 28, 3584]
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 28, 3584], num_heads=28, head_dim=128
[DEBUG] splitToHeads input data size: 100352, tensor size: 100352
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 28, 512], num_heads=4, head_dim=128
[DEBUG] splitToHeads input data size: 14336, tensor size: 14336
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 28, 512], num_heads=4, head_dim=128
[DEBUG] splitToHeads input data size: 14336, tensor size: 14336
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 4096, 512], num_heads=4, head_dim=128
[DEBUG] splitToHeads input data size: 2097152, tensor size: 2097152
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 4096, 512], num_heads=4, head_dim=128
[DEBUG] splitToHeads input data size: 2097152, tensor size: 2097152
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 3584], size=12845056, data_size=12845056
[DEBUG] Matrix dimensions: A(28x3584), B(3584x3584), batch_size=1
[DEBUG] Output shape: [1, 28, 3584]
[DEBUG] Result tensor created: size=100352, data_size=100352
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully


[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 3584], size=12845056, data_size=12845056
[DEBUG] Matrix dimensions: A(28x3584), B(3584x3584), batch_size=1
[DEBUG] Output shape: [1, 28, 3584]
[DEBUG] Result tensor created: size=100352, data_size=100352
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully
[DEBUG] Transformer layer 1 completed
[DEBUG] Processing transformer layer 2/28
[DEBUG] Input tensor shape: [1, 28, 3584]
[DEBUG] RoPE output tensor shape: [1, 28, 3584]
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 3584], size=12845056, data_size=12845056
[DEBUG] Matrix dimensions: A(28x3584), B(3584x3584), batch_size=1
[DEBUG] Output shape: [1, 28, 3584]
[DEBUG] Result tensor created: size=100352, data_size=100352
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 512], size=1835008, data_size=1835008
[DEBUG] Matrix dimensions: A(28x3584), B(3584x512), batch_size=1
[DEBUG] Output shape: [1, 28, 512]
[DEBUG] Result tensor created: size=14336, data_size=14336
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 512], size=1835008, data_size=1835008
[DEBUG] Matrix dimensions: A(28x3584), B(3584x512), batch_size=1
[DEBUG] Output shape: [1, 28, 512]
[DEBUG] Result tensor created: size=14336, data_size=14336
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully
[DEBUG] Q projection shape: [1, 28, 3584]
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 28, 3584], num_heads=28, head_dim=128
[DEBUG] splitToHeads input data size: 100352, tensor size: 100352
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 28, 512], num_heads=4, head_dim=128
[DEBUG] splitToHeads input data size: 14336, tensor size: 14336
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 28, 512], num_heads=4, head_dim=128
[DEBUG] splitToHeads input data size: 14336, tensor size: 14336
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 4096, 512], num_heads=4, head_dim=128
[DEBUG] splitToHeads input data size: 2097152, tensor size: 2097152
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 4096, 512], num_heads=4, head_dim=128
[DEBUG] splitToHeads input data size: 2097152, tensor size: 2097152
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 3584], size=12845056, data_size=12845056
[DEBUG] Matrix dimensions: A(28x3584), B(3584x3584), batch_size=1
[DEBUG] Output shape: [1, 28, 3584]
[DEBUG] Result tensor created: size=100352, data_size=100352
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully
[DEBUG] Transformer layer 2 completed
[DEBUG] Processing transformer layer 3/28
[DEBUG] Input tensor shape: [1, 28, 3584]
[DEBUG] RoPE output tensor shape: [1, 28, 3584]
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 3584], size=12845056, data_size=12845056
[DEBUG] Matrix dimensions: A(28x3584), B(3584x3584), batch_size=1
[DEBUG] Output shape: [1, 28, 3584]
[DEBUG] Result tensor created: size=100352, data_size=100352
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 512], size=1835008, data_size=1835008
[DEBUG] Matrix dimensions: A(28x3584), B(3584x512), batch_size=1
[DEBUG] Output shape: [1, 28, 512]
[DEBUG] Result tensor created: size=14336, data_size=14336
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 512], size=1835008, data_size=1835008
[DEBUG] Matrix dimensions: A(28x3584), B(3584x512), batch_size=1
[DEBUG] Output shape: [1, 28, 512]
[DEBUG] Result tensor created: size=14336, data_size=14336
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully
[DEBUG] Q projection shape: [1, 28, 3584]
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 28, 3584], num_heads=28, head_dim=128
[DEBUG] splitToHeads input data size: 100352, tensor size: 100352
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 28, 512], num_heads=4, head_dim=128
[DEBUG] splitToHeads input data size: 14336, tensor size: 14336
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 28, 512], num_heads=4, head_dim=128
[DEBUG] splitToHeads input data size: 14336, tensor size: 14336
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 4096, 512], num_heads=4, head_dim=128
[DEBUG] splitToHeads input data size: 2097152, tensor size: 2097152
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 4096, 512], num_heads=4, head_dim=128
[DEBUG] splitToHeads input data size: 2097152, tensor size: 2097152
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 3584], size=12845056, data_size=12845056
[DEBUG] Matrix dimensions: A(28x3584), B(3584x3584), batch_size=1
[DEBUG] Output shape: [1, 28, 3584]
[DEBUG] Result tensor created: size=100352, data_size=100352
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully
[DEBUG] Transformer layer 3 completed
[DEBUG] Processing transformer layer 4/28
[DEBUG] Input tensor shape: [1, 28, 3584]
[DEBUG] RoPE output tensor shape: [1, 28, 3584]
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 3584], size=12845056, data_size=12845056
[DEBUG] Matrix dimensions: A(28x3584), B(3584x3584), batch_size=1
[DEBUG] Output shape: [1, 28, 3584]
[DEBUG] Result tensor created: size=100352, data_size=100352
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 512], size=1835008, data_size=1835008
[DEBUG] Matrix dimensions: A(28x3584), B(3584x512), batch_size=1
[DEBUG] Output shape: [1, 28, 512]
[DEBUG] Result tensor created: size=14336, data_size=14336
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 512], size=1835008, data_size=1835008
[DEBUG] Matrix dimensions: A(28x3584), B(3584x512), batch_size=1
[DEBUG] Output shape: [1, 28, 512]
[DEBUG] Result tensor created: size=14336, data_size=14336
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully
[DEBUG] Q projection shape: [1, 28, 3584]
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 28, 3584], num_heads=28, head_dim=128
[DEBUG] splitToHeads input data size: 100352, tensor size: 100352
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 28, 512], num_heads=4, head_dim=128
[DEBUG] splitToHeads input data size: 14336, tensor size: 14336
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 28, 512], num_heads=4, head_dim=128
[DEBUG] splitToHeads input data size: 14336, tensor size: 14336
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 4096, 512], num_heads=4, head_dim=128
[DEBUG] splitToHeads input data size: 2097152, tensor size: 2097152
[DEBUG] splitToHeads input shape size: 3
[DEBUG] splitToHeads input shape: [1, 4096, 512], num_heads=4, head_dim=128
[DEBUG] splitToHeads input data size: 2097152, tensor size: 2097152
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] FastAttention::compute called
[DEBUG] FastAttention input validation passed
[DEBUG] FastAttention::computeStandardAttention called with seq_len_q=28, seq_len_k=1, head_dim=128
[DEBUG] Starting attention score computation...
[DEBUG] Processing query position 0/28
[DEBUG] Processing query position 10/28
[DEBUG] Processing query position 20/28
[DEBUG] Attention score computation completed
[DEBUG] performMatMul called
[DEBUG] Tensor A: shape=[1, 28, 3584], size=100352, data_size=100352
[DEBUG] Tensor B: shape=[3584, 3584], size=12845056, data_size=12845056
[DEBUG] Matrix dimensions: A(28x3584), B(3584x3584), batch_size=1
[DEBUG] Output shape: [1, 28, 3584]
[DEBUG] Result tensor created: size=100352, data_size=100352
[DEBUG] Starting matrix multiplication loops
[DEBUG] Processing batch 0
[DEBUG] Matrix multiplication completed successfully
